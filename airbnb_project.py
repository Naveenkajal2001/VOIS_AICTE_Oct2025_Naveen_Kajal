# -*- coding: utf-8 -*-
"""Airbnb Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l5UEObc_ylbuLcCwGRrMV-Jf-ehfT39z

# ***Problem Statement For AirBnb Hotel Booking:***

The hospitality industry is transforming due to online short-term lodging platforms like Airbnb.
This analysis focuses on New York City Airbnb dataset, with goals such as:

* Data cleaning and exploration

* Understanding listing availability, pricing, and customer satisfaction

* Finding relationships between property features and price

* Helping stakeholders understand Airbnb’s operations in NYC
"""

# importing the essential libraries Used in this project

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Open the file in the pandas
df=pd.read_excel('/content/1730285881-Airbnb_Open_Data.xlsx')

"""# **Questions to Answer:**

1. What are the different property types in the dataset?

2. Which neighborhood group has the highest number of listings?

3. Which neighborhood group has the higher average prices for Airbnb listings?

4. Is there a relationship between the construction year of property and price?

5. Who are the top 10 hosts with most listings?

6. Are hosts with verified identities more likely to receive positive reviews?

7. Is there a correlation between the price of a listing and service fee?

8. What is the average review rate (e.g., stars) for listings, and does it vary based on the neighborhood group and room type?

9. Are hosts with a higher calculated host listings count more likely to maintain higher availability throughout the year?

"""

df.head(3)

# retrieving the informations about the dataset
df.info()

"""***There can be problems in the data we are going to check it***

1. duplicated records in the data.

2. Missing values in some records.

3. There can be currency sign in the columns like fee.

4. The currency for price and service fee were not added to the column’s titles.



6. Columns like the price, service fee, id, host id, last review, construction year are assigned wrong datatypes.

7. In the neighborhood group column, the spelling of Brooklyn was misspelt in some records.

8. Some outliers were identified in the availability_365 column.
"""

# duplicated records in the data.
df.duplicated().value_counts()

# Missing Values can be recorded.
df.isnull().sum()

# Checking for currency sign in the columns like fee.
df['service fee'].sample(10)
df['price'].sample(10)

# Columns like the construction year are assigned wrong datatypes.
df.dtypes

# In the neighborhood group column, the spelling of Brooklyn was misspelt in some records.
df['neighbourhood group'].unique()

# brookln and manhatan

# Some outliers were identified in the columns.

# df['availability 365'].plot(kind='box')
# df['price'].plot(kind='box')
df['service fee'].plot(kind='box')

"""**CLEAN THE DATA**

**Steps to be Taken for Data Cleaning:**

1. Drop duplicated records.

2. Drop house_rules and license columns with insufficient data.

3. Rename the price and service fee columns to include a dollar sign.

4. Drop all records with missing values.

5. Change all mismatched data types to the appropriate ones.

6. Correct the spelling of brooklyn to Brooklyn manhatan to Manhattan.

7. Get rid of outliers in the availability_365 column data.
"""

# All the duplicated values are removed because it give us wrong insights for our data
df.drop_duplicates(inplace=True)

# Drop house_rules and license columns with insufficient data. These columns have more null values and than they are not useful.
df.drop(['house_rules','license'], axis=1,inplace=True)

df.head(2)

# Rename the price and service fee columns to include a dollar sign. To represents the currency in which price and fee is mentioned.
df.rename(columns={
    'price':'Price in $',
    'service fee': 'service fee in $'

},inplace=True)

# brookln is mis spelled
df.replace({'brookln':'Brooklyn',
            'manhatan':'Manhattan'},inplace=True)

# Change all mismatched data types to the appropriate ones.
df['minimum nights']=pd.to_numeric(df['minimum nights'],errors='coerce').astype('Int32')

df.isnull().sum()

df.dropna()
# if we drop na we are going to loose 18 percent of the data then we are going to fill some values and check

df.shape

df1=df.copy() # making copy of the dataset if something wrong happened then it does not affect original dataset

df1['reviews per month'].fillna(df['reviews per month'].mean(),inplace=True)
df1['last review'].fillna(df['last review'].mean(),inplace=True)

df1.dropna().shape

# now we have checked it and we can perform same operation on our dataset

df['reviews per month'].fillna(df['reviews per month'].mean(),inplace=True)
df['last review'].fillna(df['last review'].mean(),inplace=True)

df.dropna(inplace=True)

df.shape

# Get rid of outliers in the availability_365 column data.
df['availability 365'].plot(kind='box')

# removing outliers
def outliers_remove(df,col):
  Q1 = df[col].quantile(0.25)
  Q3=df[col].quantile(0.75)
  IQR=Q3-Q1
  lower_limit=Q1-1.5*IQR
  upper_limit=Q3+1.5*IQR
  df=df[(df[col]>=lower_limit) & (df[col]<=upper_limit)]
  print("The lower limit for the column is : ",lower_limit)
  print("The upper limit for the column is : ",upper_limit)
  return df

# Testing the method
outliers_remove(df=df1,col='availability 365')

df=outliers_remove(df,'availability 365')

df.shape

df.duplicated().value_counts()

# The size is reduced and the data types are changed.
df.info()

"""**Exploratory Data Analysis (EDA):**

 Helps us understand the dataset and prepare it for modeling. It includes checking the number and types of features, identifying missing values, and handling them using methods like mean or median imputation. Outliers in columns such as price or availability_365 are detected and removed using the IQR method to avoid skewing the results. EDA also examines the distribution of numerical and categorical variables using plots and charts, and studies relationships between features through correlation analysis. Additionally, new features can be created to capture useful patterns. Overall, EDA provides insights, highlights data issues, and guides data cleaning and modeling steps.
"""

df['room type'].value_counts().plot(kind='bar')

# Which neighborhood group has the highest number of listings?
df['neighbourhood group'].value_counts()

df['neighbourhood group'].value_counts().plot(kind='bar')
plt.title('Count of Listings by Neighbourhood Group')
plt.xlabel('Neighbourhood Group')
plt.ylabel('Number of Listings')

plt.show()

"""From the above graph we conclude that the Manhattan neighbourhood group have the highest number of listing."""

# Which neighborhood group has the higher average prices for Airbnb listings?
price_bar=df.groupby(['neighbourhood group'])['Price in $'].mean().to_frame()

price_bar

price_bar.plot(kind='bar')

plt.title('Average Price of neighnourhood.')
plt.xlabel('Neighbourhood Group')
plt.ylabel('Average Price')

plt.show()

"""We conclude that there is a little difference in the average price of the neighbourhoods for airnb listings."""

# Is there a relationship between the construction year of property and price?
df['Price in $'].corr(df['Construction year'])

df.groupby('Construction year')['Price in $'].mean().plot()

"""
we can say that there is no relationship between the construction year and the price column."""

# Who are the top 10 hosts with most listings?

df.groupby('host name')['calculated host listings count'].sum().sort_values(ascending=False).head(10)

df.groupby('host name')['calculated host listings count'].sum().sort_values(ascending=False).head(10).plot(kind='bar')

# Are hosts with verified identities more likely to receive positive reviews?

df.groupby('host_identity_verified')['number of reviews'].mean()

df.groupby('host_identity_verified')['number of reviews'].mean().plot(kind='bar')

"""There is no evidence from which we say that the verfied hosts can get more positive reviews."""

df.head(3)

# Is there a correlation between the price of a listing and service fee?
df['Price in $'].corr(df['service fee in $'])

sns.regplot(x='Price in $',y='service fee in $',data=df)

"""From the graph it can be seen that the price is increasing and than the service fee is also increasing so there is a positive relationship between them."""

# What is the average review rate (e.g., stars) for listings, and does it vary based on the neighborhood group and room type?

arrn=df.groupby(['neighbourhood group','room type'])['review rate number'].mean().to_frame()
arrn.unstack()

arrn.unstack().plot(kind='bar')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

"""So yes we can say that the average review rate is varried based on the neighbourhood groups.

Like
1. When neighbourhood is Brooklyn the hotel room are best. And same for Manhattan and Queens groups.
2. While When neighbourhood is Bronx and Staten Island the Hotel room doesn't get best ratings.
"""

# Are hosts with a higher calculated host listings count more likely to maintain higher availability throughout the year?
chl=df.groupby(['calculated host listings count'])['availability 365'].mean().reset_index()
chl

sns.regplot(x='calculated host listings count',y='availability 365',data=chl)

"""**We can say that this is not true that:**
> hosts with a higher calculated host listings count more likely to maintain higher availability throughout the year.


"""

